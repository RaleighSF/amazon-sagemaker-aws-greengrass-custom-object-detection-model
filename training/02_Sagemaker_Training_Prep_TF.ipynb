{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once your Groundtruth job has completed, lets prepare for training\n",
    "\n",
    "This notebook walks you through the steps we have taken to process the object detection label output from Ground Truth to prepare it for model training in SageMaker. \n",
    "\n",
    "1. [Join together outputs from multiple labeling jobs](#join_output)\n",
    "1. [Filter out labels that did not meet our quality bar](#filter_bad_labels)\n",
    "1. [Generate TFRecords for import into Tensorflow](#generate_records)\n",
    "1. [Upload Records to S3](#upload_records)\n",
    "1. [data augmentation](#data_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'cvml-sagemaker-repo'\n",
    "JOB_NAME = 'wakeboarder-detection' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os, shutil\n",
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "def make_tmp_folder(folder_name):\n",
    "    try:\n",
    "        os.makedirs(folder_name, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        print(\"{} folder already exists\".format(folder_name))\n",
    "        \n",
    "def read_manifest_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        output = [json.loads(line.strip()) for line in f.readlines()]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the Ground Truth labeling job id(s)  from the jobs section in the Sagemaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if using your own Ground Truth labeling job, replace below with appropriate job IDs\n",
    "LABEL_JOB_IDS = ['wakeboarder-detection']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp folder already exists\n"
     ]
    }
   ],
   "source": [
    "TMP_FOLDER_NAME = 'tmp' \n",
    "make_tmp_folder(TMP_FOLDER_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enable Flexibility and Join outputs from multiple jobs <a href id='join_output'></a>\n",
    "\n",
    "To be able to iterate on Ground Truth jobs, this process can join outputs from multiple jobs. You can still run this cell if you have only 1 job. \n",
    "\n",
    "The below code takes one or more Ground Truth job IDs, download the output (Augmented Manifest File format) and join them together into one array for manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://cvml-sagemaker-repo/ground_truth/output/wakeboarder-detection/manifests/output/output.manifest to tmp/wakeboarder-detection-output.manifest\n",
      "loaded 298 lines from tmp/wakeboarder-detection-output.manifest\n",
      "loaded total of 298 lines\n"
     ]
    }
   ],
   "source": [
    "joined_outputs = []\n",
    "\n",
    "def get_output_manifest_s3_uri(label_job_id):\n",
    "    # uncomment below if you are using your own Ground Truth labeling job \n",
    "     return sagemaker_client.describe_labeling_job(LabelingJobName=label_job_id)['LabelingJobOutput']['OutputDatasetS3Uri']\n",
    "\n",
    "for label_job_id in LABEL_JOB_IDS: \n",
    "    output_manifest_s3_uri = get_output_manifest_s3_uri(label_job_id)\n",
    "    output_manifest_fname = \"{}-{}\".format(label_job_id, os.path.split(output_manifest_s3_uri)[1])\n",
    "    !aws s3 cp $output_manifest_s3_uri $TMP_FOLDER_NAME/$output_manifest_fname\n",
    "    output_manifest_local_path = os.path.join(TMP_FOLDER_NAME, output_manifest_fname)\n",
    "    output_manifest_lines = read_manifest_file(output_manifest_local_path)\n",
    "    print(\"loaded {} lines from {}\".format(len(output_manifest_lines), output_manifest_local_path))\n",
    "    joined_outputs += output_manifest_lines\n",
    "    \n",
    "print(\"loaded total of {} lines\".format(len(joined_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source-ref': 's3://cvml-sagemaker-repo/frames/wakeboarding_001055.jpg',\n",
       " 'wakeboarder-detection': {'annotations': [{'class_id': 0,\n",
       "    'width': 483,\n",
       "    'top': 125,\n",
       "    'height': 544,\n",
       "    'left': 306}],\n",
       "  'image_size': [{'width': 1280, 'depth': 3, 'height': 720}]},\n",
       " 'wakeboarder-detection-metadata': {'job-name': 'labeling-job/wakeboarder-detection',\n",
       "  'class-map': {'0': 'wakeboard'},\n",
       "  'human-annotated': 'yes',\n",
       "  'objects': [{'confidence': 0.09}],\n",
       "  'creation-date': '2020-03-12T20:02:31.826196',\n",
       "  'type': 'groundtruth/object-detection'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_outputs[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source-ref': 's3://cvml-sagemaker-repo/frames/wakeboarding_018743.jpg',\n",
       " 'wakeboarder-detection': {'annotations': [],\n",
       "  'image_size': [{'width': 1280, 'depth': 3, 'height': 720}]},\n",
       " 'wakeboarder-detection-metadata': {'job-name': 'labeling-job/wakeboarder-detection',\n",
       "  'class-map': {},\n",
       "  'human-annotated': 'yes',\n",
       "  'objects': [],\n",
       "  'creation-date': '2020-03-12T20:45:58.452830',\n",
       "  'type': 'groundtruth/object-detection'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_outputs[-15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MANUAL REVIEW: Discard any bad labels from visual inspection <a href id=\"filter_bad_labels\"></a>\n",
    "\n",
    "In the __Sagemaker console__, under labeling jobs, select your completed labeling job name. Review any images that don't meet the quality bar and you can remove them from the list by placing them in the list array below: (remove any .jpg file extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_DISCARD = set([\n",
    "    'wakeboarding_003299',\n",
    "    'wakeboarding_007127',\n",
    "    'wakeboarding_007391',\n",
    "    'wakeboarding_008183',\n",
    "    'wakeboarding_008777',\n",
    "    'wakeboarding_013331',\n",
    "    'wakeboarding_013397',\n",
    "    'wakeboarding_013925',\n",
    "    'wakeboarding_015905',\n",
    "    'wakeboarding_015971',\n",
    "    'wakeboarding_017555',\n",
    "    'wakeboarding_017753',\n",
    "    'wakeboarding_017819',\n",
    "    'wakeboarding_018149',\n",
    "    'wakeboarding_018611',\n",
    "    'wakeboarding_018677',\n",
    "    'wakeboarding_018743',\n",
    "    'wakeboarding_019535'\n",
    "\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered out 18 labels. 280 labels remains\n"
     ]
    }
   ],
   "source": [
    "filtered_manifest = []\n",
    "recover_list = []\n",
    "count_filtered = 0\n",
    "for line in joined_outputs:\n",
    "    filename= os.path.split(line[\"source-ref\"])[1]\n",
    "    imageid = os.path.splitext(filename)[0]\n",
    "    if imageid not in TO_DISCARD:\n",
    "        filtered_manifest.append(line)\n",
    "        recover_list.append(filename)\n",
    "    else:\n",
    "        count_filtered+=1    \n",
    "print(\"filtered out {} labels. {} labels remains\".format(count_filtered, len(filtered_manifest)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for image in recover_list:\n",
    "    s3.Bucket('cvml-sagemaker-repo').download_file('frames/{}'.format(image), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TF Records for Tensorflow <a href id='generate_records'></a\n",
    "\n",
    "Recall the folder where images were extracted from our video in the last notebook, and set the FULL __IMAGE_PATH__ in the cell following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/amazon-sagemaker-aws-greengrass-custom-object-detection-model/data-prep/tmp/wakeboarding/\r\n"
     ]
    }
   ],
   "source": [
    "!ls -d /home/ec2-user/SageMaker/amazon-sagemaker-aws-greengrass-custom-object-detection-model/data-prep/tmp/*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/scrubbed.manifest\n"
     ]
    }
   ],
   "source": [
    "#Create a reference to the images stored locally\n",
    "IMAGE_PATH = '/home/ec2-user/SageMaker/amazon-sagemaker-aws-greengrass-custom-object-detection-model/data-prep/tmp/wakeboarding'\n",
    "\n",
    "# Write out the updated manifest from above in memory list activities\n",
    "SCRUBBED_MANIFEST = './{}/scrubbed.manifest'.format(TMP_FOLDER_NAME)\n",
    "\n",
    "with open(SCRUBBED_MANIFEST, 'w') as f:\n",
    "    for item in filtered_manifest:\n",
    "        f.write(json.dumps(item))\n",
    "        f.write('\\n')\n",
    "print(SCRUBBED_MANIFEST)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp/tf_records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#Create a local directory to hold the output of the TF Record process\n",
    "!mkdir $TMP_FOLDER_NAME/tf_records\n",
    "OUTPUT_DIR = './{}/tf_records'.format(TMP_FOLDER_NAME)\n",
    "\n",
    "#Create class mapping here - e.g. - each class ID should map to the human readable equivalent\n",
    "LABEL_MAP = {'0': 'wakeboard'}\n",
    "print(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please read - a TODO:\n",
    "The below code calls upon a file [tf_record_util.py](./utils/tf_record_util.py), that is responsible for managing the binary assembly and split of the dataset into a single TFRecord. This file has a hardcoded class value that needs to be reworked to be more dynamic. You can view the contents of this file in the appendix below, if you like. Note the reference to __'annotation_dict['wakeboarder-detection']['annotations'])'__ which needs to be changed to your class annotation if different. [View file here](#appendix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING TF RECORD FILES\n",
      "GENERATING LABEL MAP FILE\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils.tf_record_util import TfRecordGenerator\n",
    "\n",
    "# Feed in necessary path variables from above operations\n",
    "tf_record_generator = TfRecordGenerator(image_dir=IMAGE_PATH,\n",
    "                                        manifest=SCRUBBED_MANIFEST,\n",
    "                                        label_map=LABEL_MAP,\n",
    "                                        output_dir=OUTPUT_DIR)\n",
    "\n",
    "print('GENERATING TF RECORD FILES')\n",
    "tf_record_generator.generate_tf_records()\n",
    "\n",
    "print('GENERATING LABEL MAP FILE')\n",
    "with open(f'{OUTPUT_DIR}/label_map.pbtxt', 'w') as label_map_file:\n",
    "    for item in LABEL_MAP:\n",
    "        label_map_file.write('item {\\n')\n",
    "        label_map_file.write(' id: ' + str(int(item) + 1) + '\\n')\n",
    "        label_map_file.write(\" name: '\" + LABEL_MAP[item] + \"'\\n\")\n",
    "        label_map_file.write('}\\n\\n')\n",
    "        \n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload TFRecords AND LABEL MAP TO S3  <a href id='upload_records'></a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(BUCKET).upload_file(f'{OUTPUT_DIR}/label_map.pbtxt', 'tfrecords/label_map.pbtxt')\n",
    "s3.Bucket(BUCKET).upload_file(f'{OUTPUT_DIR}/train.records', 'tfrecords/train.records')\n",
    "s3.Bucket(BUCKET).upload_file(f'{OUTPUT_DIR}/validation.records', 'tfrecords/validation.records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SKIP: Optional Data augmentation <a href id='data_aug'></a> (NOT YET ADAPTED TO TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run ./flip_images.py -m s3://$BUCKET/training-manifest/$JOB_NAME/train.manifest -d $TMP_FOLDER_NAME -b $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./flip_annotations.py -m s3://$BUCKET/training-manifest/$JOB_NAME/train.manifest -d $TMP_FOLDER_NAME -p $JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step\n",
    "\n",
    "Now we are ready to start training jobs! Move on to the [next notebook](./03_Sagemaker_Training_TF.ipynb) to submit a sagemaker training job to train our custom object detection model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informational Appendix: <a href id=\"appendix\"></a>\n",
    "\n",
    "The cell below reveals the content of the to-be-reworked TFRecord converter. It works, but requires manual update to account for the desired class name (yes, only 1 class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.highlight .hll { background-color: #ffffcc }\n",
       ".highlight  { background: #f8f8f8; }\n",
       ".highlight .c { color: #408080; font-style: italic } /* Comment */\n",
       ".highlight .err { border: 1px solid #FF0000 } /* Error */\n",
       ".highlight .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".highlight .o { color: #666666 } /* Operator */\n",
       ".highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".highlight .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".highlight .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".highlight .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".highlight .ge { font-style: italic } /* Generic.Emph */\n",
       ".highlight .gr { color: #FF0000 } /* Generic.Error */\n",
       ".highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".highlight .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".highlight .go { color: #888888 } /* Generic.Output */\n",
       ".highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".highlight .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #B00040 } /* Keyword.Type */\n",
       ".highlight .m { color: #666666 } /* Literal.Number */\n",
       ".highlight .s { color: #BA2121 } /* Literal.String */\n",
       ".highlight .na { color: #7D9029 } /* Name.Attribute */\n",
       ".highlight .nb { color: #008000 } /* Name.Builtin */\n",
       ".highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".highlight .no { color: #880000 } /* Name.Constant */\n",
       ".highlight .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".highlight .nf { color: #0000FF } /* Name.Function */\n",
       ".highlight .nl { color: #A0A000 } /* Name.Label */\n",
       ".highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".highlight .nv { color: #19177C } /* Name.Variable */\n",
       ".highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".highlight .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".highlight .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #008000 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">os</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">io</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">json</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">jsonlines</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">random</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">logging</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">utils</span> <span class=\"kn\">import</span> <span class=\"n\">dataset_util</span>\n",
       "<span class=\"kn\">from</span> <span class=\"nn\">PIL</span> <span class=\"kn\">import</span> <span class=\"n\">Image</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"kn\">as</span> <span class=\"nn\">tf</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">TfRecordGenerator</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__init__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">image_dir</span><span class=\"p\">,</span> <span class=\"n\">manifest</span><span class=\"p\">,</span> <span class=\"n\">label_map</span><span class=\"p\">,</span> <span class=\"n\">output_dir</span><span class=\"p\">):</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">image_dir</span> <span class=\"o\">=</span> <span class=\"n\">image_dir</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">manifest</span> <span class=\"o\">=</span> <span class=\"n\">manifest</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">label_map</span> <span class=\"o\">=</span> <span class=\"n\">label_map</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">output_dir</span> <span class=\"o\">=</span> <span class=\"n\">output_dir</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">generate_tf_records</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">with</span> <span class=\"n\">jsonlines</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">manifest</span><span class=\"p\">,</span> <span class=\"s1\">&#39;r&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">reader</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">ground_truth_annotations</span> <span class=\"o\">=</span> <span class=\"nb\">list</span><span class=\"p\">(</span><span class=\"n\">reader</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"n\">split_dataset</span><span class=\"p\">(</span><span class=\"n\">ground_truth_annotations</span><span class=\"p\">)</span>\n",
       "            <span class=\"k\">for</span> <span class=\"n\">subset</span> <span class=\"ow\">in</span> <span class=\"n\">dataset</span><span class=\"p\">:</span>\n",
       "                <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"s1\">&#39;GENERATING TF RECORD FOR {subset}&#39;</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">writer</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">TFRecordWriter</span><span class=\"p\">(</span><span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">path</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">output_dir</span><span class=\"p\">,</span> <span class=\"n\">f</span><span class=\"s1\">&#39;{subset}.records&#39;</span><span class=\"p\">))</span>\n",
       "                <span class=\"k\">for</span> <span class=\"n\">image_annotations</span> <span class=\"ow\">in</span> <span class=\"n\">dataset</span><span class=\"p\">[</span><span class=\"n\">subset</span><span class=\"p\">]:</span>\n",
       "                    <span class=\"n\">annotation_dict</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">image_annotations</span><span class=\"p\">))</span>\n",
       "                    <span class=\"n\">tf_example</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_create_tf_example</span><span class=\"p\">(</span><span class=\"n\">annotation_dict</span><span class=\"p\">[</span><span class=\"s1\">&#39;source-ref&#39;</span><span class=\"p\">],</span>\n",
       "                                                         <span class=\"n\">annotation_dict</span><span class=\"p\">[</span><span class=\"s1\">&#39;wakeboarder-detection&#39;</span><span class=\"p\">][</span><span class=\"s1\">&#39;annotations&#39;</span><span class=\"p\">])</span>\n",
       "                    <span class=\"n\">writer</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">tf_example</span><span class=\"o\">.</span><span class=\"n\">SerializeToString</span><span class=\"p\">())</span>\n",
       "                <span class=\"n\">writer</span><span class=\"o\">.</span><span class=\"n\">close</span><span class=\"p\">()</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">_create_tf_example</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">s3_image_path</span><span class=\"p\">,</span> <span class=\"n\">annotations</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">image_name</span> <span class=\"o\">=</span> <span class=\"n\">s3_image_path</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(</span><span class=\"s1\">&#39;/&#39;</span><span class=\"p\">)[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
       "        <span class=\"n\">image_path</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"s1\">&#39;{self.image_dir}/{image_name}&#39;</span>\n",
       "        <span class=\"n\">im</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">)</span>\n",
       "        <span class=\"c1\">#print(im.size)</span>\n",
       "        <span class=\"c1\"># READ IMAGE FILE</span>\n",
       "        <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">gfile</span><span class=\"o\">.</span><span class=\"n\">GFile</span><span class=\"p\">(</span><span class=\"n\">image_path</span><span class=\"p\">,</span> <span class=\"s1\">&#39;rb&#39;</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">fid</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">encoded_jpg</span> <span class=\"o\">=</span> <span class=\"n\">fid</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n",
       "        <span class=\"n\">encoded_jpg_io</span> <span class=\"o\">=</span> <span class=\"n\">io</span><span class=\"o\">.</span><span class=\"n\">BytesIO</span><span class=\"p\">(</span><span class=\"n\">encoded_jpg</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">encoded_jpg_io</span><span class=\"o\">.</span><span class=\"n\">seek</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">Image</span><span class=\"o\">.</span><span class=\"n\">open</span><span class=\"p\">(</span><span class=\"n\">encoded_jpg_io</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">image_width</span><span class=\"p\">,</span> <span class=\"n\">image_height</span> <span class=\"o\">=</span> <span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">size</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">format</span> <span class=\"o\">!=</span> <span class=\"s1\">&#39;JPEG&#39;</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">image</span> <span class=\"o\">=</span> <span class=\"n\">image</span><span class=\"o\">.</span><span class=\"n\">convert</span><span class=\"p\">(</span><span class=\"s1\">&#39;RGB&#39;</span><span class=\"p\">)</span>\n",
       "            <span class=\"c1\">#print(image_path)</span>\n",
       "            <span class=\"c1\">#raise ValueError(&#39;Image format not JPEG&#39;)</span>\n",
       "\n",
       "        <span class=\"n\">xmins</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"n\">ymins</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"n\">xmaxs</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"n\">ymaxs</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"n\">classes</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"n\">classes_text</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">a</span> <span class=\"ow\">in</span> <span class=\"n\">annotations</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">x</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"p\">[</span><span class=\"s1\">&#39;left&#39;</span><span class=\"p\">]</span>\n",
       "            <span class=\"n\">y</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"p\">[</span><span class=\"s1\">&#39;top&#39;</span><span class=\"p\">]</span>\n",
       "            <span class=\"n\">width</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"p\">[</span><span class=\"s1\">&#39;width&#39;</span><span class=\"p\">]</span>\n",
       "            <span class=\"n\">height</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"p\">[</span><span class=\"s1\">&#39;height&#39;</span><span class=\"p\">]</span>\n",
       "            <span class=\"n\">class_id</span> <span class=\"o\">=</span> <span class=\"n\">a</span><span class=\"p\">[</span><span class=\"s1\">&#39;class_id&#39;</span><span class=\"p\">]</span>\n",
       "            <span class=\"n\">xmins</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">image_width</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">xmaxs</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">x</span> <span class=\"o\">+</span> <span class=\"n\">width</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">image_width</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">ymins</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">image_height</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">ymaxs</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"nb\">float</span><span class=\"p\">(</span><span class=\"n\">y</span> <span class=\"o\">+</span> <span class=\"n\">height</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">image_height</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">class_name</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">label_map</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">(</span><span class=\"n\">class_id</span><span class=\"p\">)]</span>\n",
       "            <span class=\"n\">classes_text</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">class_name</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s1\">&#39;utf8&#39;</span><span class=\"p\">))</span>\n",
       "            <span class=\"n\">classes</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">class_id</span><span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"n\">feature_dict</span> <span class=\"o\">=</span> <span class=\"p\">{</span>\n",
       "            <span class=\"s1\">&#39;image/height&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">int64_feature</span><span class=\"p\">(</span><span class=\"n\">image_height</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/width&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">int64_feature</span><span class=\"p\">(</span><span class=\"n\">image_width</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/filename&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">bytes_feature</span><span class=\"p\">(</span><span class=\"nb\">bytes</span><span class=\"p\">(</span><span class=\"n\">image_name</span><span class=\"p\">,</span> <span class=\"s1\">&#39;utf-8&#39;</span><span class=\"p\">)),</span>\n",
       "            <span class=\"s1\">&#39;image/source_id&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">bytes_feature</span><span class=\"p\">(</span><span class=\"nb\">bytes</span><span class=\"p\">(</span><span class=\"n\">image_name</span><span class=\"o\">.</span><span class=\"n\">replace</span><span class=\"p\">(</span><span class=\"s1\">&#39;.jpg&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;&#39;</span><span class=\"p\">),</span> <span class=\"s1\">&#39;utf-8&#39;</span><span class=\"p\">)),</span>\n",
       "            <span class=\"s1\">&#39;image/encoded&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">bytes_feature</span><span class=\"p\">(</span><span class=\"n\">encoded_jpg</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/format&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">bytes_feature</span><span class=\"p\">(</span><span class=\"s1\">&#39;jpeg&#39;</span><span class=\"o\">.</span><span class=\"n\">encode</span><span class=\"p\">(</span><span class=\"s1\">&#39;utf8&#39;</span><span class=\"p\">)),</span>\n",
       "            <span class=\"s1\">&#39;image/object/bbox/xmin&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">float_list_feature</span><span class=\"p\">(</span><span class=\"n\">xmins</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/object/bbox/xmax&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">float_list_feature</span><span class=\"p\">(</span><span class=\"n\">xmaxs</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/object/bbox/ymin&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">float_list_feature</span><span class=\"p\">(</span><span class=\"n\">ymins</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/object/bbox/ymax&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">float_list_feature</span><span class=\"p\">(</span><span class=\"n\">ymaxs</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/object/class/text&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">bytes_list_feature</span><span class=\"p\">(</span><span class=\"n\">classes_text</span><span class=\"p\">),</span>\n",
       "            <span class=\"s1\">&#39;image/object/class/label&#39;</span><span class=\"p\">:</span> <span class=\"n\">dataset_util</span><span class=\"o\">.</span><span class=\"n\">int64_list_feature</span><span class=\"p\">(</span><span class=\"n\">classes</span><span class=\"p\">),</span>\n",
       "        <span class=\"p\">}</span>\n",
       "        <span class=\"n\">example</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">Example</span><span class=\"p\">(</span><span class=\"n\">features</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">Features</span><span class=\"p\">(</span><span class=\"n\">feature</span><span class=\"o\">=</span><span class=\"n\">feature_dict</span><span class=\"p\">))</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">example</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">split_dataset</span><span class=\"p\">(</span><span class=\"n\">list_images</span><span class=\"p\">):</span>\n",
       "    <span class=\"n\">dataset</span> <span class=\"o\">=</span> <span class=\"p\">{}</span>\n",
       "    <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">seed</span><span class=\"p\">(</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">shuffle</span><span class=\"p\">(</span><span class=\"n\">list_images</span><span class=\"p\">)</span>\n",
       "    <span class=\"n\">num_train</span> <span class=\"o\">=</span> <span class=\"nb\">int</span><span class=\"p\">(</span><span class=\"mf\">0.9</span> <span class=\"o\">*</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">list_images</span><span class=\"p\">))</span>\n",
       "    <span class=\"n\">dataset</span><span class=\"p\">[</span><span class=\"s1\">&#39;train&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">list_images</span><span class=\"p\">[:</span><span class=\"n\">num_train</span><span class=\"p\">]</span>\n",
       "    <span class=\"n\">dataset</span><span class=\"p\">[</span><span class=\"s1\">&#39;validation&#39;</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">list_images</span><span class=\"p\">[</span><span class=\"n\">num_train</span><span class=\"p\">:]</span>\n",
       "    <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"n\">f</span><span class=\"s1\">&#39;TRAINING EXAMPLES: </span><span class=\"si\">%d</span><span class=\"s1\"> - VALIDATION EXAMPLES: </span><span class=\"si\">%d</span><span class=\"s1\">&#39;</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">[</span><span class=\"s1\">&#39;train&#39;</span><span class=\"p\">]),</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">[</span><span class=\"s1\">&#39;validation&#39;</span><span class=\"p\">]))</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">dataset</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "import IPython\n",
    "\n",
    "with open('./utils/tf_record_util.py') as f:\n",
    "    code = f.read()\n",
    "\n",
    "formatter = HtmlFormatter()\n",
    "IPython.display.HTML('<style type=\"text/css\">{}</style>{}'.format(\n",
    "    formatter.get_style_defs('.highlight'),\n",
    "    highlight(code, PythonLexer(), formatter)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
